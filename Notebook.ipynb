{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier, cv, DMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('./train.csv/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define target variable with three classes: 0 (Model A wins), 1 (Model B wins), 2 (Tie)\n",
    "data['target'] = np.where(data['winner_model_a'] == 1, 0, np.where(data['winner_model_b'] == 1, 1, 2))\n",
    "\n",
    "data = data.drop(['winner_model_a', 'winner_model_b', 'winner_tie'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id             model_a              model_b  \\\n",
      "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
      "1   53567           koala-13b           gpt-4-0613   \n",
      "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
      "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
      "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  [\"Is it morally right to try to have a certain...   \n",
      "1  [\"What is the difference between marriage lice...   \n",
      "2  [\"explain function calling. how would you call...   \n",
      "3  [\"How can I create a test set for a very rare ...   \n",
      "4  [\"What is the best way to travel from Tel-Aviv...   \n",
      "\n",
      "                                          response_a  \\\n",
      "0  [\"The question of whether it is morally right ...   \n",
      "1  [\"A marriage license is a legal document that ...   \n",
      "2  [\"Function calling is the process of invoking ...   \n",
      "3  [\"Creating a test set for a very rare category...   \n",
      "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
      "\n",
      "                                          response_b  target  prompt_length  \\\n",
      "0  [\"As an AI, I don't have personal beliefs or o...       0            165   \n",
      "1  [\"A marriage license and a marriage certificat...       1            200   \n",
      "2  [\"Function calling is the process of invoking ...       2             60   \n",
      "3  [\"When building a classifier for a very rare c...       0             87   \n",
      "4  [\"The best way to travel from Tel-Aviv to Jeru...       1             79   \n",
      "\n",
      "   response_a_length  response_b_length  prompt_word_count  \\\n",
      "0               4538               1206                 28   \n",
      "1               3114               3649                 35   \n",
      "2                921               1835                  9   \n",
      "3               3182               1562                 18   \n",
      "4               1300                772                 14   \n",
      "\n",
      "   response_a_word_count  response_b_word_count  prompt_response_a_similarity  \\\n",
      "0                    656                    204                      0.036360   \n",
      "1                    531                    571                      0.064226   \n",
      "2                    138                    280                      0.065147   \n",
      "3                    536                    265                      0.027341   \n",
      "4                    230                    122                      0.060769   \n",
      "\n",
      "   prompt_response_b_similarity  \n",
      "0                      0.136816  \n",
      "1                      0.054810  \n",
      "2                      0.032698  \n",
      "3                      0.055698  \n",
      "4                      0.102332  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature engineering: text lengths and basic similarity approximations\n",
    "data['prompt_length'] = data['prompt'].apply(len)\n",
    "data['response_a_length'] = data['response_a'].apply(len)\n",
    "data['response_b_length'] = data['response_b'].apply(len)\n",
    "data['prompt_word_count'] = data['prompt'].apply(lambda x: len(x.split()))\n",
    "data['response_a_word_count'] = data['response_a'].apply(lambda x: len(x.split()))\n",
    "data['response_b_word_count'] = data['response_b'].apply(lambda x: len(x.split()))\n",
    "data['prompt_response_a_similarity'] = data['prompt_length'] / (data['response_a_length'] + 1e-5)\n",
    "data['prompt_response_b_similarity'] = data['prompt_length'] / (data['response_b_length'] + 1e-5)\n",
    "\n",
    "# Define features and target variable\n",
    "features = data[['prompt_length', 'response_a_length', 'response_b_length',\n",
    "                 'prompt_word_count', 'response_a_word_count', 'response_b_word_count',\n",
    "                 'prompt_response_a_similarity', 'prompt_response_b_similarity']]\n",
    "target = data['target']\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ANOTHER TRY OF FEATURES ENGIREERING\n",
    "# Combine text columns into one\n",
    "data['combined_text'] = data['prompt'] + \" \" + data['response_a'] + \" \" + data['response_b']\n",
    "\n",
    "# Apply TF-IDF\n",
    "tfidf_combined = TfidfVectorizer(max_features=10000, ngram_range=(3, 6), stop_words='english')\n",
    "# TfidfVectorizer(analyzer='char', ngram_range=(3, 6), max_features=1000)\n",
    "tfidf_matrix = tfidf_combined.fit_transform(data['combined_text'])\n",
    "tfidf_features = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_combined.get_feature_names_out())\n",
    "\n",
    "# Define features and target\n",
    "X = tfidf_features\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.3588204592901879\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.78      0.49      4030\n",
      "           1       0.34      0.15      0.21      3929\n",
      "           2       0.42      0.11      0.17      3537\n",
      "\n",
      "    accuracy                           0.36     11496\n",
      "   macro avg       0.37      0.35      0.29     11496\n",
      "weighted avg       0.37      0.36      0.30     11496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize XGBoost with basic parameters\n",
    "xgb_model = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmerror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train final model with optimal parameters\u001b[39;00m\n\u001b[0;32m     24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:570\u001b[0m, in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks_container\u001b[38;5;241m.\u001b[39mbefore_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m should_break \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39mafter_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    573\u001b[0m res \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39maggregated_cv\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:229\u001b[0m, in \u001b[0;36m_PackedBooster.update\u001b[1;34m(self, iteration, obj)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterate through folds for update\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvfolds:\n\u001b[1;32m--> 229\u001b[0m     \u001b[43mfold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:215\u001b[0m, in \u001b[0;36mCVPack.update\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, fobj: Optional[Objective]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \"Update the boosters for one iteration\"\"\"\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create DMatrix\n",
    "dtrain = DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.4,\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    nfold=5,\n",
    "    metrics=\"merror\",\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# Train final model with optimal parameters\n",
    "best_params = params.copy()\n",
    "best_params.update({'num_boost_round': len(cv_results)})\n",
    "final_model = XGBClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized XGBoost Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Best model from grid search\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred_best \u001b[38;5;241m=\u001b[39m best_xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Best model from grid search\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_best = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Optimized XGBoost Accuracy: {accuracy_best}\")\n",
    "print(\"Optimized Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
